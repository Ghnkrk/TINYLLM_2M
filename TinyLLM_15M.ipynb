{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ghnkrk/TINYLLM/blob/main/TinyLLM_15M.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btGWgOv48rP7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6bd5b4f-5651-4af7-ef2b-5a1b6f7ab6f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'TINYLLM_2M'...\n",
            "remote: Enumerating objects: 74, done.\u001b[K\n",
            "remote: Counting objects: 100% (74/74), done.\u001b[K\n",
            "remote: Compressing objects: 100% (68/68), done.\u001b[K\n",
            "remote: Total 74 (delta 36), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (74/74), 30.44 KiB | 133.00 KiB/s, done.\n",
            "Resolving deltas: 100% (36/36), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Ghnkrk/TINYLLM_2M"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd TINYLLM_2M"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCcCb2NM6Ckf",
        "outputId": "b0d60a9e-6caf-4028-9111-24065b1b7c75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/TINYLLM_2M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nee6HmOI9wIk",
        "outputId": "d355a34f-306c-43c4-edb6-268a7870c1e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (0.24.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (2.9.0+cu126)\n",
            "Requirement already satisfied: datasets>=2.16.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (4.0.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (0.36.0)\n",
            "Requirement already satisfied: sentencepiece>=0.1.99 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (0.2.1)\n",
            "Requirement already satisfied: wandb>=0.16.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 10)) (0.23.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 11)) (4.67.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 13)) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.5.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->-r requirements.txt (line 2)) (11.3.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.16.0->-r requirements.txt (line 5)) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.16.0->-r requirements.txt (line 5)) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets>=2.16.0->-r requirements.txt (line 5)) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.16.0->-r requirements.txt (line 5)) (2.32.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets>=2.16.0->-r requirements.txt (line 5)) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.16.0->-r requirements.txt (line 5)) (0.70.16)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets>=2.16.0->-r requirements.txt (line 5)) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.16.0->-r requirements.txt (line 5)) (6.0.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->-r requirements.txt (line 6)) (1.2.0)\n",
            "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.16.0->-r requirements.txt (line 10)) (8.3.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.16.0->-r requirements.txt (line 10)) (3.1.45)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb>=0.16.0->-r requirements.txt (line 10)) (4.5.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.16.0->-r requirements.txt (line 10)) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.16.0->-r requirements.txt (line 10)) (2.12.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.16.0->-r requirements.txt (line 10)) (2.47.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->-r requirements.txt (line 5)) (3.13.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.16.0->-r requirements.txt (line 10)) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb>=0.16.0->-r requirements.txt (line 10)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb>=0.16.0->-r requirements.txt (line 10)) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb>=0.16.0->-r requirements.txt (line 10)) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=2.16.0->-r requirements.txt (line 5)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=2.16.0->-r requirements.txt (line 5)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=2.16.0->-r requirements.txt (line 5)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=2.16.0->-r requirements.txt (line 5)) (2025.11.12)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->-r requirements.txt (line 1)) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=2.16.0->-r requirements.txt (line 5)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=2.16.0->-r requirements.txt (line 5)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=2.16.0->-r requirements.txt (line 5)) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->-r requirements.txt (line 5)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->-r requirements.txt (line 5)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->-r requirements.txt (line 5)) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->-r requirements.txt (line 5)) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->-r requirements.txt (line 5)) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->-r requirements.txt (line 5)) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.16.0->-r requirements.txt (line 5)) (1.22.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.16.0->-r requirements.txt (line 10)) (5.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->-r requirements.txt (line 5)) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python tokenizer/train_tokenizer.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUVwRSPJ-lKp",
        "outputId": "759a1457-4540-41d7-c6a7-9e4d456d4c8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üî§ Training SentencePiece tokenizer\n",
            "Dataset      : simplewiki\n",
            "Vocab size   : 10000\n",
            "Save prefix  : /content/TINYLLM_2M/tokenizer/tokenizer10m_sp\n",
            "\n",
            "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
            "trainer_spec {\n",
            "  input: /content/TINYLLM_2M/tokenizer/corpus.txt\n",
            "  input_format: \n",
            "  model_prefix: /content/TINYLLM_2M/tokenizer/tokenizer10m_sp\n",
            "  model_type: BPE\n",
            "  vocab_size: 10000\n",
            "  self_test_sample_size: 0\n",
            "  character_coverage: 1\n",
            "  input_sentence_size: 0\n",
            "  shuffle_input_sentence: 1\n",
            "  seed_sentencepiece_size: 1000000\n",
            "  shrinking_factor: 0.75\n",
            "  max_sentence_length: 4192\n",
            "  num_threads: 16\n",
            "  num_sub_iterations: 2\n",
            "  max_sentencepiece_length: 16\n",
            "  split_by_unicode_script: 1\n",
            "  split_by_number: 1\n",
            "  split_by_whitespace: 1\n",
            "  split_digits: 1\n",
            "  pretokenization_delimiter: \n",
            "  treat_whitespace_as_suffix: 0\n",
            "  allow_whitespace_only_pieces: 0\n",
            "  required_chars: \n",
            "  byte_fallback: 0\n",
            "  vocabulary_output_piece_score: 1\n",
            "  train_extremely_large_corpus: 0\n",
            "  seed_sentencepieces_file: \n",
            "  hard_vocab_limit: 1\n",
            "  use_all_vocab: 0\n",
            "  unk_id: 1\n",
            "  bos_id: -1\n",
            "  eos_id: -1\n",
            "  pad_id: 0\n",
            "  unk_piece: <unk>\n",
            "  bos_piece: <s>\n",
            "  eos_piece: </s>\n",
            "  pad_piece: <pad>\n",
            "  unk_surface:  ‚Åá \n",
            "  enable_differential_privacy: 0\n",
            "  differential_privacy_noise_level: 0\n",
            "  differential_privacy_clipping_threshold: 0\n",
            "}\n",
            "normalizer_spec {\n",
            "  name: nmt_nfkc\n",
            "  add_dummy_prefix: 1\n",
            "  remove_extra_whitespaces: 1\n",
            "  escape_whitespaces: 1\n",
            "  normalization_rule_tsv: \n",
            "}\n",
            "denormalizer_spec {}\n",
            "trainer_interface.cc(355) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
            "trainer_interface.cc(186) LOG(INFO) Loading corpus: /content/TINYLLM_2M/tokenizer/corpus.txt\n",
            "trainer_interface.cc(382) LOG(WARNING) Found too long line (16109 > 4192).\n",
            "trainer_interface.cc(384) LOG(WARNING) Too long lines are skipped in the training.\n",
            "trainer_interface.cc(385) LOG(WARNING) The maximum length can be changed with --max_sentence_length=<size> flag.\n",
            "trainer_interface.cc(411) LOG(INFO) Loaded all 233104 sentences\n",
            "trainer_interface.cc(418) LOG(INFO) Skipped 8659 too long sentences.\n",
            "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: <pad>\n",
            "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: <unk>\n",
            "trainer_interface.cc(432) LOG(INFO) Normalizing sentences...\n",
            "trainer_interface.cc(541) LOG(INFO) all chars count=168478727\n",
            "trainer_interface.cc(552) LOG(INFO) Done: 100% characters are covered.\n",
            "trainer_interface.cc(562) LOG(INFO) Alphabet size=5674\n",
            "trainer_interface.cc(563) LOG(INFO) Final character coverage=1\n",
            "trainer_interface.cc(594) LOG(INFO) Done! preprocessed 233104 sentences.\n",
            "trainer_interface.cc(600) LOG(INFO) Tokenizing input sentences with whitespace: 233104\n",
            "trainer_interface.cc(611) LOG(INFO) Done! 1215779\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2463678 min_freq=183\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=983329 size=20 all=40116 active=4487 piece=al\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=525466 size=40 all=42455 active=6826 piece=‚ñÅd\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=353867 size=60 all=44974 active=9345 piece=el\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=259207 size=80 all=48065 active=12436 piece=ch\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=214632 size=100 all=51214 active=15585 piece=ig\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=214279 min_freq=3374\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=174805 size=120 all=54627 active=5731 piece=‚ñÅU\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=139019 size=140 all=56947 active=8051 piece=‚ñÅSt\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=119042 size=160 all=59478 active=10582 piece=ak\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=102586 size=180 all=62953 active=14057 piece=‚ñÅit\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=89802 size=200 all=66145 active=17249 piece=so\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=88085 min_freq=2776\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=80018 size=220 all=69830 active=6837 piece=ors\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=69438 size=240 all=72299 active=9306 piece=end\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=63716 size=260 all=75198 active=12205 piece=ac\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=55972 size=280 all=79088 active=16095 piece=ational\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=51400 size=300 all=81728 active=18735 piece=‚ñÅex\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=51230 min_freq=2130\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=47848 size=320 all=84132 active=6428 piece=).\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=44220 size=340 all=86679 active=8975 piece=ens\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=42056 size=360 all=90255 active=12551 piece=lect\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=38490 size=380 all=92415 active=14711 piece=ivers\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=36187 size=400 all=95566 active=17862 piece=ram\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=35982 min_freq=1695\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=33949 size=420 all=97423 active=6396 piece=act\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=32522 size=440 all=99714 active=8687 piece=‚ñÅAust\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=30631 size=460 all=101842 active=10815 piece=‚ñÅmus\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=28926 size=480 all=103793 active=12766 piece=ile\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=27814 size=500 all=105971 active=14944 piece=‚ñÅafter\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=27648 min_freq=1466\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=26486 size=520 all=107561 active=6878 piece=‚ñÅPr\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=25571 size=540 all=110046 active=9363 piece=fer\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=24767 size=560 all=111293 active=10610 piece=hip\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=23648 size=580 all=113484 active=12801 piece=‚ñÅMay\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22741 size=600 all=115031 active=14348 piece=‚ñÅCal\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=22716 min_freq=1296\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21834 size=620 all=116608 active=7208 piece=‚ñÅestablishments\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21039 size=640 all=117525 active=8125 piece=artment\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20281 size=660 all=119303 active=9903 piece=angu\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19678 size=680 all=121531 active=12131 piece=‚ñÅlar\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19055 size=700 all=122858 active=13458 piece=ener\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=19054 min_freq=1178\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18677 size=720 all=124888 active=8044 piece=ica\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18193 size=740 all=127579 active=10735 piece=ouse\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17608 size=760 all=128918 active=12074 piece=‚ñÅthan\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17028 size=780 all=130777 active=13933 piece=‚ñÅOr\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16576 size=800 all=132441 active=15597 piece=‚ñÅwhere\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=16567 min_freq=1036\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16131 size=820 all=133550 active=7722 piece=‚ñÅnational\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15512 size=840 all=135036 active=9208 piece=pen\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15177 size=860 all=136093 active=10265 piece=com\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14795 size=880 all=137642 active=11814 piece=‚ñÅvery\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14430 size=900 all=139176 active=13348 piece=ants\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=14426 min_freq=959\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13939 size=920 all=141083 active=8719 piece=efore\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13524 size=940 all=143079 active=10715 piece=dom\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13156 size=960 all=144989 active=12625 piece=ger\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12815 size=980 all=147395 active=15031 piece=‚ñÅpopulation\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12529 size=1000 all=148937 active=16573 piece=‚ñÅcons\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=12528 min_freq=856\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12228 size=1020 all=149745 active=8225 piece=ific\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11883 size=1040 all=151098 active=9578 piece=ield\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11617 size=1060 all=152851 active=11331 piece=‚ñÅcompan\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11237 size=1080 all=154955 active=13435 piece=‚ñÅrep\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11029 size=1100 all=155911 active=14391 piece=con\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=11015 min_freq=788\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10739 size=1120 all=157995 active=9668 piece=||||||||\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10518 size=1140 all=159599 active=11272 piece=the\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10281 size=1160 all=160708 active=12381 piece=by\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10088 size=1180 all=162407 active=14080 piece=ajor\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9859 size=1200 all=164321 active=15994 piece=‚ñÅsever\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=9857 min_freq=736\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9596 size=1220 all=166117 active=10001 piece=‚ñÅMich\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9451 size=1240 all=167225 active=11109 piece=‚ñÅsim\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9216 size=1260 all=169275 active=13159 piece=‚ñÅvers\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8972 size=1280 all=171226 active=15110 piece=‚ñÅhead\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8807 size=1300 all=172277 active=16161 piece=‚ñÅcensus\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=8805 min_freq=682\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8710 size=1320 all=173280 active=9615 piece=‚ñÅspecies\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8492 size=1340 all=174255 active=10590 piece=‚ñÅhome\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8315 size=1360 all=176124 active=12459 piece=‚ñÅkill\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8141 size=1380 all=177979 active=14314 piece=‚ñÅfrog\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7997 size=1400 all=179243 active=15578 piece=sociation\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=7994 min_freq=637\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7821 size=1420 all=180789 active=10502 piece=ush\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7724 size=1440 all=181931 active=11644 piece=‚ñÅaward\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7632 size=1460 all=182585 active=12298 piece=rick\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7486 size=1480 all=184096 active=13809 piece=ler\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7332 size=1500 all=185767 active=15480 piece=‚ñÅVal\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=7325 min_freq=596\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7229 size=1520 all=187487 active=10877 piece=‚ñÅPaul\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=7067 size=1540 all=188791 active=12181 piece=led\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6974 size=1560 all=190181 active=13571 piece=‚ñÅMor\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6862 size=1580 all=191204 active=14594 piece=oung\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6735 size=1600 all=193289 active=16679 piece=‚ñÅrec\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6719 min_freq=560\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6629 size=1620 all=194854 active=11181 piece=uter\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6539 size=1640 all=195988 active=12315 piece=‚ñÅBest\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6470 size=1660 all=197058 active=13385 piece=‚ñÅRich\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6373 size=1680 all=198880 active=15207 piece=fecture\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6287 size=1700 all=199881 active=16208 piece=‚ñÅbig\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=6285 min_freq=529\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6177 size=1720 all=201127 active=11223 piece=ona\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6109 size=1740 all=203078 active=13174 piece=‚ñÅgood\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=6042 size=1760 all=203591 active=13687 piece=eum\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5956 size=1780 all=204710 active=14806 piece=‚ñÅGeorg\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5836 size=1800 all=205594 active=15690 piece=ours\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5833 min_freq=502\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5736 size=1820 all=206687 active=11269 piece=‚ñÅVill\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5643 size=1840 all=207629 active=12211 piece=liam\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5568 size=1860 all=208835 active=13417 piece=‚ñÅSam\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5492 size=1880 all=209923 active=14505 piece=‚ñÅusing\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5412 size=1900 all=211028 active=15610 piece=atives\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5411 min_freq=482\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5362 size=1920 all=211739 active=11233 piece=ting\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5296 size=1940 all=212826 active=12320 piece=‚ñÅMexico\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5219 size=1960 all=214606 active=14100 piece=‚ñÅAss\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5160 size=1980 all=215497 active=14991 piece=‚ñÅline\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5096 size=2000 all=216294 active=15788 piece=‚ñÅAtl\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=5089 min_freq=460\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=5015 size=2020 all=217519 active=12020 piece=St\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4948 size=2040 all=218603 active=13104 piece=‚ñÅChurch\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4903 size=2060 all=219316 active=13817 piece=hest\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4832 size=2080 all=220882 active=15383 piece=‚ñÅcharacters\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4771 size=2100 all=221703 active=16204 piece=ta\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4771 min_freq=440\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4729 size=2120 all=223203 active=12359 piece=‚ñÅexpl\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4690 size=2140 all=224361 active=13517 piece=‚ñÅright\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4647 size=2160 all=225470 active=14626 piece=‚ñÅhand\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4587 size=2180 all=226346 active=15502 piece=‚ñÅOh\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4533 size=2200 all=227820 active=16976 piece=‚ñÅice\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4532 min_freq=420\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4475 size=2220 all=229330 active=12899 piece=‚ñÅPrize\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4430 size=2240 all=230444 active=14013 piece=‚ñÅPeter\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4386 size=2260 all=231069 active=14638 piece=‚ñÅside\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4340 size=2280 all=231884 active=15453 piece=‚ñÅsent\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4302 size=2300 all=233058 active=16627 piece=ibr\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4302 min_freq=404\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4267 size=2320 all=234084 active=12621 piece=‚ñÅmult\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4225 size=2340 all=235147 active=13684 piece=‚ñÅwhite\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4157 size=2360 all=236715 active=15252 piece=awa\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4125 size=2380 all=238189 active=16726 piece=‚ñÅthose\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4089 size=2400 all=239166 active=17703 piece=ogn\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=4089 min_freq=387\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4065 size=2420 all=240334 active=12981 piece=‚ñÅEarly\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=4029 size=2440 all=241247 active=13894 piece=‚ñÅexper\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3980 size=2460 all=241971 active=14618 piece=ellow\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3945 size=2480 all=242841 active=15488 piece=umn\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3910 size=2500 all=243807 active=16454 piece=‚ñÅArmy\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3906 min_freq=375\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3873 size=2520 all=245041 active=13421 piece=be\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3842 size=2540 all=246475 active=14855 piece=‚ñÅMuseum\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3790 size=2560 all=247338 active=15718 piece=‚ñÅfinal\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3746 size=2580 all=248225 active=16605 piece=ences\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3717 size=2600 all=249015 active=17395 piece=uf\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3717 min_freq=360\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3670 size=2620 all=249917 active=13073 piece=volution\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3624 size=2640 all=251121 active=14277 piece=‚ñÅRob\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3584 size=2660 all=252038 active=15194 piece=iy\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3549 size=2680 all=253201 active=16357 piece=‚ñÅSenate\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3507 size=2700 all=254394 active=17550 piece=aps\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3506 min_freq=346\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3470 size=2720 all=255393 active=13581 piece=estival\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3440 size=2740 all=256266 active=14454 piece=‚ñÅUs\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3415 size=2760 all=257490 active=15678 piece=‚ñÅinf\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3386 size=2780 all=258165 active=16353 piece=cul\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3355 size=2800 all=259140 active=17328 piece=‚ñÅcompanies\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3354 min_freq=335\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3326 size=2820 all=259725 active=13542 piece=‚ñÅBir\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3303 size=2840 all=260806 active=14623 piece=ella\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3271 size=2860 all=262190 active=16007 piece=‚ñÅSocial\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3236 size=2880 all=262528 active=16345 piece=ny\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3211 size=2900 all=263903 active=17720 piece=ros\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3209 min_freq=322\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3188 size=2920 all=265352 active=14359 piece=‚ñÅfar\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3158 size=2940 all=266322 active=15329 piece=viron\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3131 size=2960 all=267295 active=16302 piece=val\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3098 size=2980 all=269374 active=18381 piece=://\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3067 size=3000 all=269998 active=19005 piece=uit\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=3066 min_freq=310\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3027 size=3020 all=270907 active=14285 piece=‚ñÅder\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3011 size=3040 all=271481 active=14859 piece=‚ñÅgoal\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2997 size=3060 all=272231 active=15609 piece=‚ñÅindependent\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2977 size=3080 all=273299 active=16677 piece=‚ñÅCensus\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2943 size=3100 all=273800 active=17178 piece=pring\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2941 min_freq=302\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2910 size=3120 all=274267 active=14114 piece=Fran\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2885 size=3140 all=274819 active=14666 piece=ricket\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2865 size=3160 all=276046 active=15893 piece=‚ñÅfif\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2838 size=3180 all=276870 active=16717 piece=‚ñÅRome\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2812 size=3200 all=277574 active=17421 piece=‚ñÅjob\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2811 min_freq=294\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2794 size=3220 all=278875 active=15174 piece=EFA\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2766 size=3240 all=279289 active=15588 piece=ply\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2736 size=3260 all=280043 active=16342 piece=‚ñÅAssembly\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2719 size=3280 all=280980 active=17279 piece=‚ñÅcase\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2697 size=3300 all=281463 active=17762 piece=back\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2697 min_freq=285\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2683 size=3320 all=281926 active=14423 piece=‚ñÅMem\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2661 size=3340 all=282758 active=15255 piece=‚ñÅCompany\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2642 size=3360 all=283491 active=15988 piece=‚ñÅsomething\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2622 size=3380 all=284171 active=16668 piece=√©e\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2607 size=3400 all=285263 active=17760 piece=inals\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2606 min_freq=278\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2586 size=3420 all=286460 active=15443 piece=‚ñÅscientists\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2573 size=3440 all=287251 active=16234 piece=‚ñÅtheory\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2555 size=3460 all=288047 active=17030 piece=‚ñÅToronto\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2534 size=3480 all=288583 active=17566 piece=‚ñÅcollege\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2519 size=3500 all=289460 active=18443 piece=‚ñÅPu\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2519 min_freq=271\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2500 size=3520 all=290308 active=15247 piece=‚ñÅFer\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2484 size=3540 all=290890 active=15829 piece=atter\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2468 size=3560 all=291673 active=16612 piece=‚ñÅAzerbai\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2454 size=3580 all=292240 active=17179 piece=‚ñÅdead\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2437 size=3600 all=293056 active=17995 piece=‚ñÅarmy\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2435 min_freq=265\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2424 size=3620 all=293967 active=15564 piece=sen\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2403 size=3640 all=294912 active=16509 piece=ising\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2382 size=3660 all=295845 active=17442 piece=‚ñÅassociation\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2352 size=3680 all=296392 active=17989 piece=adelphia\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2329 size=3700 all=296871 active=18468 piece=elt\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2329 min_freq=258\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2317 size=3720 all=298264 active=16089 piece=‚ñÅdu\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2300 size=3740 all=299008 active=16833 piece=ums\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2284 size=3760 all=299935 active=17760 piece=‚ñÅWall\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2271 size=3780 all=300770 active=18595 piece=head\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2250 size=3800 all=302147 active=19972 piece=‚ñÅpsych\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2249 min_freq=250\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2235 size=3820 all=302836 active=15768 piece=‚ñÅVideo\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2223 size=3840 all=303331 active=16263 piece=‚ñÅrad\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2208 size=3860 all=303993 active=16925 piece=elled\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2194 size=3880 all=304626 active=17558 piece=‚ñÅcur\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2180 size=3900 all=305811 active=18743 piece=‚ñÅconstitu\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2179 min_freq=244\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2165 size=3920 all=306873 active=16348 piece=‚ñÅspoken\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2149 size=3940 all=307378 active=16853 piece=‚ñÅenough\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2130 size=3960 all=308566 active=18041 piece=‚ñÅGard\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2111 size=3980 all=309611 active=19086 piece=istant\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2099 size=4000 all=310465 active=19940 piece=‚ñÅSon\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2099 min_freq=236\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2088 size=4020 all=311301 active=16276 piece=‚ñÅcapt\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2072 size=4040 all=311900 active=16875 piece=ero\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2061 size=4060 all=312911 active=17886 piece=‚ñÅlove\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2047 size=4080 all=313811 active=18786 piece=‚ñÅUSA\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2040 size=4100 all=314425 active=19400 piece=‚ñÅGreece\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2039 min_freq=230\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2023 size=4120 all=315206 active=16502 piece=‚ñÅSpace\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2006 size=4140 all=315859 active=17155 piece=apore\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1996 size=4160 all=316697 active=17993 piece=‚ñÅAndrew\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1981 size=4180 all=317324 active=18620 piece=‚ñÅbronze\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1966 size=4200 all=317723 active=19019 piece=‚ñÅOpen\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1966 min_freq=226\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1952 size=4220 all=318309 active=16440 piece=lad\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1944 size=4240 all=319284 active=17415 piece=‚ñÅcommer\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1934 size=4260 all=319912 active=18043 piece=‚ñÅgovern\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1921 size=4280 all=320361 active=18492 piece=‚ñÅsexual\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1907 size=4300 all=320954 active=19085 piece=‚ñÅofficer\n",
            "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1907 min_freq=221\n",
            "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1895 size=4320 all=321575 active=16669 piece=‚ñÅHeart\n",
            "trainer_interface.cc(689) LOG(INFO) Saving model: /content/TINYLLM_2M/tokenizer/tokenizer10m_sp.model\n",
            "trainer_interface.cc(701) LOG(INFO) Saving vocabs: /content/TINYLLM_2M/tokenizer/tokenizer10m_sp.vocab\n",
            "‚úÖ Tokenizer training complete\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python param_count.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPm5dN3E-8xZ",
        "outputId": "2cad44b7-6ade-4ad4-ef50-268ab5c43236"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Model Parameter Summary\n",
            "-------------------------\n",
            "Experiment      : tinylm_10m\n",
            "Vocab size      : 10000\n",
            "Total params    : 15,399,184 (15.40M)\n",
            "Trainable params: 15,399,184 (15.40M)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_I6wariZFKo9",
        "outputId": "445b1a33-14b3-4c7d-e140-7edfb2411381"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üöÄ Using device: cuda\n",
            "\n",
            "Enter your Weights & Biases API key: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mguhan-karthik25\u001b[0m (\u001b[33mguhan-karthik25-kumaraguru-college-of-technology\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m setting up run 55xmbgp7 (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m setting up run 55xmbgp7 (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m setting up run 55xmbgp7 (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m setting up run 55xmbgp7 (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m setting up run 55xmbgp7 (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/TINYLLM_2M/wandb/run-20251214_114505-55xmbgp7\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mtinylm_10m\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/guhan-karthik25-kumaraguru-college-of-technology/TinyLLM10M\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/guhan-karthik25-kumaraguru-college-of-technology/TinyLLM10M/runs/55xmbgp7\u001b[0m\n",
            "Tokenizer vocab size: 10000\n",
            "Train samples: 348413 | Val samples: 7110\n",
            "Model parameters: 15.40M\n",
            "/content/TINYLLM_2M/train.py:128: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=train_cfg[\"mixed_precision\"])\n",
            "\n",
            "üî• Training started\n",
            "\n",
            "Epoch 1:   0% 0/5444 [00:00<?, ?it/s]/content/TINYLLM_2M/train.py:153: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=train_cfg[\"mixed_precision\"]):\n",
            "Epoch 1:   9% 499/5444 [01:42<16:58,  4.86it/s, loss=6.3988, lr=2.49e-05, ppl=601.10]\n",
            "üîé Step 500 | Val Loss: 6.6486 | Val PPL: 771.74\n",
            "\n",
            "üíæ Best model saved\n",
            "Epoch 1:  18% 999/5444 [03:40<14:59,  4.94it/s, loss=4.8027, lr=5.00e-05, ppl=121.84]\n",
            "üîé Step 1000 | Val Loss: 5.1668 | Val PPL: 175.35\n",
            "\n",
            "üíæ Best model saved\n",
            "Epoch 1:  28% 1499/5444 [05:37<13:21,  4.92it/s, loss=4.5942, lr=7.50e-05, ppl=98.91]\n",
            "üîé Step 1500 | Val Loss: 4.5502 | Val PPL: 94.65\n",
            "\n",
            "üíæ Best model saved\n",
            "Epoch 1:  37% 1999/5444 [07:35<11:37,  4.94it/s, loss=4.2982, lr=1.00e-04, ppl=73.57]\n",
            "üîé Step 2000 | Val Loss: 4.1641 | Val PPL: 64.33\n",
            "\n",
            "üíæ Best model saved\n",
            "Epoch 1:  46% 2499/5444 [09:32<09:56,  4.93it/s, loss=3.9863, lr=9.98e-05, ppl=53.86]\n",
            "üîé Step 2500 | Val Loss: 3.9031 | Val PPL: 49.56\n",
            "\n",
            "üíæ Best model saved\n",
            "Epoch 1:  55% 2999/5444 [11:30<08:16,  4.93it/s, loss=3.6257, lr=9.92e-05, ppl=37.55]\n",
            "üîé Step 3000 | Val Loss: 3.7418 | Val PPL: 42.17\n",
            "\n",
            "üíæ Best model saved\n",
            "Epoch 1:  64% 3499/5444 [13:27<06:33,  4.94it/s, loss=3.4600, lr=9.83e-05, ppl=31.82]\n",
            "üîé Step 3500 | Val Loss: 3.6265 | Val PPL: 37.58\n",
            "\n",
            "üíæ Best model saved\n",
            "Epoch 1:  73% 3999/5444 [15:25<04:53,  4.93it/s, loss=3.4622, lr=9.70e-05, ppl=31.89]\n",
            "üîé Step 4000 | Val Loss: 3.5324 | Val PPL: 34.21\n",
            "\n",
            "üíæ Best model saved\n",
            "Epoch 1:  83% 4499/5444 [17:23<03:11,  4.94it/s, loss=3.2171, lr=9.53e-05, ppl=24.96]\n",
            "üîé Step 4500 | Val Loss: 3.4506 | Val PPL: 31.52\n",
            "\n",
            "üíæ Best model saved\n",
            "Epoch 1:  92% 4999/5444 [19:20<01:30,  4.90it/s, loss=3.5412, lr=9.33e-05, ppl=34.51]\n",
            "üîé Step 5000 | Val Loss: 3.3801 | Val PPL: 29.37\n",
            "\n",
            "üíæ Best model saved\n",
            "Epoch 1: 100% 5444/5444 [21:06<00:00,  4.30it/s, loss=3.3898, lr=9.12e-05, ppl=29.66]\n",
            "Epoch 2:   1% 55/5444 [00:11<18:14,  4.92it/s, loss=3.4306, lr=9.10e-05, ppl=30.90]\n",
            "üîé Step 5500 | Val Loss: 3.3231 | Val PPL: 27.75\n",
            "\n",
            "üíæ Best model saved\n",
            "Epoch 2:  10% 555/5444 [02:08<16:32,  4.93it/s, loss=3.3039, lr=8.83e-05, ppl=27.22]\n",
            "üîé Step 6000 | Val Loss: 3.2738 | Val PPL: 26.41\n",
            "\n",
            "Epoch 2:  19% 1055/5444 [04:06<14:48,  4.94it/s, loss=3.0618, lr=8.54e-05, ppl=21.37]\n",
            "üîé Step 6500 | Val Loss: 3.2318 | Val PPL: 25.32\n",
            "\n",
            "üíæ Best model saved\n",
            "Epoch 2:  29% 1555/5444 [06:04<13:09,  4.92it/s, loss=3.1051, lr=8.21e-05, ppl=22.31]\n",
            "üîé Step 7000 | Val Loss: 3.1934 | Val PPL: 24.37\n",
            "\n",
            "Epoch 2:  38% 2055/5444 [08:01<11:25,  4.95it/s, loss=3.2050, lr=7.87e-05, ppl=24.66]\n",
            "üîé Step 7500 | Val Loss: 3.1601 | Val PPL: 23.57\n",
            "\n",
            "üíæ Best model saved\n",
            "Epoch 2:  47% 2555/5444 [09:59<09:45,  4.93it/s, loss=3.0232, lr=7.50e-05, ppl=20.56]\n",
            "üîé Step 8000 | Val Loss: 3.1305 | Val PPL: 22.89\n",
            "\n",
            "Epoch 2:  56% 3055/5444 [11:56<08:03,  4.94it/s, loss=3.1276, lr=7.11e-05, ppl=22.82]\n",
            "üîé Step 8500 | Val Loss: 3.1031 | Val PPL: 22.27\n",
            "\n",
            "üíæ Best model saved\n",
            "Epoch 2:  65% 3555/5444 [13:54<06:22,  4.94it/s, loss=2.9276, lr=6.71e-05, ppl=18.68]\n",
            "üîé Step 9000 | Val Loss: 3.0783 | Val PPL: 21.72\n",
            "\n",
            "Epoch 2:  74% 4055/5444 [15:51<04:41,  4.93it/s, loss=3.1206, lr=6.29e-05, ppl=22.66]\n",
            "üîé Step 9500 | Val Loss: 3.0595 | Val PPL: 21.32\n",
            "\n",
            "Epoch 2:  84% 4555/5444 [17:49<03:00,  4.92it/s, loss=3.1554, lr=5.87e-05, ppl=23.46]\n",
            "üîé Step 10000 | Val Loss: 3.0383 | Val PPL: 20.87\n",
            "\n",
            "üíæ Best model saved\n",
            "Epoch 2:  93% 5055/5444 [19:46<01:18,  4.93it/s, loss=3.0911, lr=5.44e-05, ppl=22.00]\n",
            "üîé Step 10500 | Val Loss: 3.0211 | Val PPL: 20.51\n",
            "\n",
            "Epoch 2: 100% 5444/5444 [21:21<00:00,  4.25it/s, loss=2.7228, lr=5.10e-05, ppl=15.22]\n",
            "Epoch 3:   2% 111/5444 [00:22<17:59,  4.94it/s, loss=3.0603, lr=5.00e-05, ppl=21.33]\n",
            "üîé Step 11000 | Val Loss: 3.0063 | Val PPL: 20.21\n",
            "\n",
            "Epoch 3:  11% 611/5444 [02:20<16:16,  4.95it/s, loss=2.8416, lr=4.57e-05, ppl=17.14]\n",
            "üîé Step 11500 | Val Loss: 2.9913 | Val PPL: 19.91\n",
            "\n",
            "Epoch 3:  20% 1111/5444 [04:17<14:39,  4.93it/s, loss=2.9200, lr=4.13e-05, ppl=18.54]\n",
            "üîé Step 12000 | Val Loss: 2.9763 | Val PPL: 19.61\n",
            "\n",
            "üíæ Best model saved\n",
            "Epoch 3:  30% 1611/5444 [06:15<12:55,  4.94it/s, loss=3.2472, lr=3.71e-05, ppl=25.72]\n",
            "üîé Step 12500 | Val Loss: 2.9660 | Val PPL: 19.41\n",
            "\n",
            "Epoch 3:  39% 2111/5444 [08:12<11:15,  4.93it/s, loss=2.9680, lr=3.29e-05, ppl=19.45]\n",
            "üîé Step 13000 | Val Loss: 2.9546 | Val PPL: 19.19\n",
            "\n",
            "Epoch 3:  48% 2611/5444 [10:10<09:33,  4.94it/s, loss=2.9506, lr=2.89e-05, ppl=19.12]\n",
            "üîé Step 13500 | Val Loss: 2.9448 | Val PPL: 19.01\n",
            "\n",
            "Epoch 3:  57% 3111/5444 [12:07<07:52,  4.94it/s, loss=2.7211, lr=2.50e-05, ppl=15.20]\n",
            "üîé Step 14000 | Val Loss: 2.9363 | Val PPL: 18.85\n",
            "\n",
            "‚èπ Early stopping triggered (step-based)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m updating run metadata (0.0s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading output.log 2.7KB/2.7KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading wandb-summary.json 269B/269B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading output.log 2.7KB/2.7KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading wandb-summary.json 269B/269B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading output.log 2.7KB/2.7KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading wandb-summary.json 269B/269B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading output.log 2.7KB/2.7KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading wandb-summary.json 269B/269B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading output.log 2.7KB/2.7KB (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading wandb-summary.json 269B/269B (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading wandb-summary.json 269B/269B (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m uploading config.yaml 3.2KB/3.2KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading wandb-summary.json 269B/269B (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m uploading config.yaml 3.2KB/3.2KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading wandb-summary.json 269B/269B (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m uploading config.yaml 3.2KB/3.2KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading wandb-summary.json 269B/269B (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading config.yaml 3.2KB/3.2KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading wandb-summary.json 269B/269B (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ø\u001b[0m uploading config.yaml 3.2KB/3.2KB (0.4s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ü\u001b[0m uploading history steps 14027-14027, summary, console lines 93-113 (...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚°ø\u001b[0m uploading history steps 14027-14027, summary, console lines 93-113 (...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m uploading history steps 14027-14027, summary, console lines 93-113 (...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               lr ‚ñÅ‚ñÇ‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             step ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/loss ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/perplexity ‚ñà‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/loss ‚ñà‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   val/perplexity ‚ñà‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               lr 3e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:             step 14000\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/loss 2.72107\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: train/perplexity 15.19661\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/loss 2.93628\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   val/perplexity 18.8457\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mtinylm_10m\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/guhan-karthik25-kumaraguru-college-of-technology/TinyLLM10M/runs/55xmbgp7\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at: \u001b[34m\u001b[4mhttps://wandb.ai/guhan-karthik25-kumaraguru-college-of-technology/TinyLLM10M\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251214_114505-55xmbgp7/logs\u001b[0m\n",
            "Epoch 3:  57% 3111/5444 [12:25<09:18,  4.17it/s, loss=2.7211, lr=2.50e-05, ppl=15.20]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from datasets import load_dataset\n",
        "import sentencepiece as spm\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "import os\n",
        "import json\n",
        "import sys\n",
        "\n",
        "# Explicitly change Python's working directory to TINYLLM_2M\n",
        "os.chdir('TINYLLM_2M')\n",
        "\n",
        "# Assuming DecoderOnlyTransformer definition is in Architecture.py\n",
        "from Architecture import DecoderOnlyTransformer\n",
        "\n",
        "# --- Configuration ---\n",
        "# These parameters will be loaded from config_20M.json\n",
        "CONFIG_FILE = \"config_20M.json\"\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "BATCH_SIZE = 16    # Batch size for validation\n",
        "TOKENIZER_MODEL_PATH = \"tokenizer/tokenizer10m_sp.model\"\n",
        "BEST_MODEL_PATH = \"best_model.pt\"\n",
        "\n",
        "print(f\"üöÄ Using device: {DEVICE}\")\n",
        "\n",
        "# --- Load Config ---\n",
        "print(f\"Loading configuration from {CONFIG_FILE}...\")\n",
        "try:\n",
        "    with open(CONFIG_FILE, 'r') as f:\n",
        "        config = json.load(f)\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Config file '{CONFIG_FILE}' not found. Please ensure it's in the current directory.\")\n",
        "    exit()\n",
        "except json.JSONDecodeError:\n",
        "    print(f\"Error: Could not decode JSON from '{CONFIG_FILE}'. Please check file integrity.\")\n",
        "    exit()\n",
        "\n",
        "# Extract parameters from config\n",
        "VOCAB_SIZE = config.get(\"vocab_size\", 10000)\n",
        "MODEL_DIM = config.get(\"model_dim\", 256)\n",
        "NUM_HEADS = config.get(\"num_heads\", 8)\n",
        "NUM_LAYERS = config.get(\"num_layers\", 6)\n",
        "MAX_SEQ_LEN = config.get(\"max_seq_len\", 256) # Used for data processing, not passed to model constructor directly\n",
        "DROPOUT = config.get(\"dropout\", 0.1)\n",
        "# Extract d_ffn from config as it's a required argument\n",
        "D_FFN = config.get(\"model\", {}).get(\"d_ffn\", 1024)\n",
        "\n",
        "print(f\"Loaded config: Vocab Size={VOCAB_SIZE}, Model Dim={MODEL_DIM}, Num Heads={NUM_HEADS}, Num Layers={NUM_LAYERS}, Max Seq Len={MAX_SEQ_LEN}, d_ffn={D_FFN}\")\n",
        "\n",
        "# --- Load Tokenizer ---\n",
        "print(\"Loading tokenizer...\")\n",
        "try:\n",
        "    tokenizer = spm.SentencePieceProcessor(model_file=TOKENIZER_MODEL_PATH)\n",
        "except Exception as e:\n",
        "    print(f\"Error loading tokenizer: {e}\")\n",
        "    print(\"Please ensure 'tokenizer/tokenizer10m_sp.model' exists and is correctly generated.\")\n",
        "    exit()\n",
        "\n",
        "# --- Load Validation Dataset ---\n",
        "print(\"Loading validation dataset...\")\n",
        "try:\n",
        "    # Load the main dataset split, then create a validation split from it\n",
        "    # This mimics the common practice of splitting a 'train' set for training and validation\n",
        "    full_dataset = load_dataset(\"wikimedia/wikipedia\", \"20231101.simple\", split=\"train\")\n",
        "    # Create a small validation split (e.g., 1% of the data) for evaluation consistency\n",
        "    # Adjust test_size as needed, or load a predefined 'validation' split if your dataset has one\n",
        "    split_dataset = full_dataset.train_test_split(test_size=0.01, seed=42) # Using a small test_size for validation\n",
        "    dataset = split_dataset['test'] # Use the 'test' split as our validation set\n",
        "except Exception as e:\n",
        "    print(f\"Error loading dataset: {e}\")\n",
        "    print(\"Please ensure the dataset path and split are correct, or verify internet connectivity for Hugging Face datasets.\")\n",
        "    exit()\n",
        "\n",
        "# Tokenization function\n",
        "def tokenize_function(examples):\n",
        "    # Ensure 'text' column exists in your dataset\n",
        "    return {\"input_ids\": tokenizer.encode_as_ids(examples[\"text\"])}\n",
        "\n",
        "# Apply tokenization and remove original text column\n",
        "tokenized_dataset = dataset.map(tokenize_function, batched=True, remove_columns=dataset.column_names)\n",
        "tokenized_dataset.set_format(type=\"torch\", columns=[\"input_ids\"])\n",
        "\n",
        "# Collate function for DataLoader\n",
        "def collate_fn(batch):\n",
        "    # Pad sequences to MAX_SEQ_LEN\n",
        "    input_ids = [torch.tensor(x[\"input_ids\"][:MAX_SEQ_LEN], dtype=torch.long) for x in batch]\n",
        "    # Pad with the tokenizer's pad_id\n",
        "    input_ids = torch.nn.utils.rnn.pad_sequence(input_ids, batch_first=True, padding_value=tokenizer.pad_id())\n",
        "    return input_ids\n",
        "\n",
        "val_dataloader = DataLoader(tokenized_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
        "\n",
        "# --- Instantiate and Load Model ---\n",
        "print(\"Instantiating model...\")\n",
        "try:\n",
        "    model = DecoderOnlyTransformer(\n",
        "        vocab_size=VOCAB_SIZE,\n",
        "        d_model=MODEL_DIM,\n",
        "        num_heads=NUM_HEADS,\n",
        "        num_layers=NUM_LAYERS,\n",
        "        d_ffn=D_FFN # Pass the d_ffn parameter\n",
        "    ).to(DEVICE)\n",
        "except Exception as e:\n",
        "    print(f\"Error instantiating model: {e}\")\n",
        "    print(\"Please ensure 'Architecture.py' exists and the 'DecoderOnlyTransformer' class is correctly defined with matching parameters from config.\")\n",
        "    exit()\n",
        "\n",
        "if os.path.exists(BEST_MODEL_PATH):\n",
        "    print(f\"Loading best model weights from {BEST_MODEL_PATH}\")\n",
        "    try:\n",
        "        model.load_state_dict(torch.load(BEST_MODEL_PATH, map_location=DEVICE))\n",
        "        model.eval() # Set model to evaluation mode\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model state_dict: {e}\")\n",
        "        print(\"The model architecture might not match the saved weights, or the file is corrupted.\")\n",
        "        exit()\n",
        "else:\n",
        "    print(f\"Error: {BEST_MODEL_PATH} not found. Please ensure the model was trained and saved.\")\n",
        "    exit()\n",
        "\n",
        "# --- Define Loss Function ---\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_id())\n",
        "\n",
        "# --- Validation Function ---\n",
        "def validate_model(model, dataloader, criterion, device):\n",
        "    total_loss = 0.0\n",
        "    total_nll = 0.0 # Total negative log-likelihood for perplexity\n",
        "    total_tokens = 0\n",
        "\n",
        "    model.eval() # Ensure model is in evaluation mode\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Validating\"):\n",
        "            if batch.size(1) < 2: # Skip batches with less than 2 tokens for input/target split\n",
        "                continue\n",
        "\n",
        "            inputs = batch[:, :-1].to(device)\n",
        "            targets = batch[:, 1:].to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # Reshape outputs for loss calculation: (batch_size * seq_len, vocab_size)\n",
        "            outputs = outputs.view(-1, outputs.size(-1))\n",
        "            targets = targets.view(-1)\n",
        "\n",
        "            # Filter out padding tokens for loss and perplexity calculation\n",
        "            active_loss = targets != tokenizer.pad_id()\n",
        "            active_outputs = outputs[active_loss]\n",
        "            active_targets = targets[active_loss]\n",
        "\n",
        "            if active_targets.numel() == 0: # Skip if no active tokens\n",
        "                continue\n",
        "\n",
        "            loss = criterion(active_outputs, active_targets)\n",
        "\n",
        "            total_loss += loss.item() * active_targets.numel() # Accumulate loss based on number of active elements\n",
        "            total_tokens += active_targets.numel()\n",
        "\n",
        "    if total_tokens == 0:\n",
        "        print(\"No active tokens processed for validation. Check dataset and padding.\")\n",
        "        return float('inf'), float('inf') # Return infinity for no valid data\n",
        "\n",
        "    avg_loss = total_loss / total_tokens\n",
        "    perplexity = math.exp(avg_loss) if avg_loss < float('inf') else float('inf')\n",
        "    return avg_loss, perplexity\n",
        "\n",
        "print(\"Starting validation...\")\n",
        "val_loss, val_ppl = validate_model(model, val_dataloader, criterion, DEVICE)\n",
        "\n",
        "print(f\"\\n‚úÖ Validation complete!\")\n",
        "print(f\"Validation Loss: {val_loss:.4f}\")\n",
        "print(f\"Validation Perplexity: {val_ppl:.4f}\")"
      ],
      "metadata": {
        "id": "RjVzV52iUPwc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329,
          "referenced_widgets": [
            "718ff638b37142bbb29f0f307b37a9ce",
            "a6d2ddb682554dc0a988b53fad64412a",
            "118389bc467840b7b0cfcb36caa818a8",
            "9629d52f04954a7ca810767b468e7b12",
            "3ee156f2db574c09bc61e83f1e39153c",
            "b1d007268c55490985090336043b3505",
            "2c4864af0e08473cb42fff9e86373646",
            "4bdfd90e60454ec79f6fa85a4905cc7a",
            "89cbff3c3ad6458baae212d3129c1e83",
            "a08fc833b9e6401f84c7147332266426",
            "3828202c09364a94830324f04a82be56"
          ]
        },
        "outputId": "f3bf1a94-315d-43f6-bd9c-1e1cfaa35167"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Using device: cuda\n",
            "Loading configuration from config_20M.json...\n",
            "Loaded config: Vocab Size=10000, Model Dim=256, Num Heads=8, Num Layers=6, Max Seq Len=256, d_ffn=1024\n",
            "Loading tokenizer...\n",
            "Loading validation dataset...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2418 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "718ff638b37142bbb29f0f307b37a9ce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instantiating model...\n",
            "Loading best model weights from best_model.pt\n",
            "Starting validation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating:   0%|          | 0/152 [00:00<?, ?it/s]/tmp/ipython-input-624522849.py:89: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  input_ids = [torch.tensor(x[\"input_ids\"][:MAX_SEQ_LEN], dtype=torch.long) for x in batch]\n",
            "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 152/152 [00:05<00:00, 25.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Validation complete!\n",
            "Validation Loss: 3.1802\n",
            "Validation Perplexity: 24.0506\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!python inference.py --prompt \"In order to\" --max_new_tokens 256 --temperature 0.6 --top_k 40 --top_p 0.95 --repetition_penalty 1.2"
      ],
      "metadata": {
        "id": "u0klwdleGral",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c5cce3d-16db-4418-acdc-73559f9a5c51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üöÄ Inference on tinylm_10m (cuda)\n",
            "\n",
            "\n",
            "üß† Model output:\n",
            "\n",
            "In order to be able to work for the powers and drive themselves. They have a very good brain, like tasks or wildlife. These are not always known as \"brother\" or \"new\" (originally called \"the most common in the world\". This is when a person is used by people with them or fertilizing water from any utilities which can be seen on the way of the body. Someone may also get better than the same things as they do not live in their own. The people who believe that you want to go and tell her. The word 'word' are different from this problem. One example of the slower is the mind (hydration) that has been made. It does not know what he is now partly because it is a bigger clear that is a hair of people in the United States and the United States. The term was first used in 1937. This is a book written for an option, but there is no evidence of about 50 years old. The book also describes some books to be the first novel of the same name. The\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3_-lRROjjS3r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
